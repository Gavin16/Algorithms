################################################ 一 Kafka(3.0) (精通) ################################################

1. Kafka 批量发送消息是如何存储的？批量消息是否需要批量消费? 压缩消息呢？
Kafka 批量发送或者压缩发送的消息都是按照发送过来的形式进行存储，并不做数据的解批或者解压缩处理.
由于存储就是按照批量进行的，消费者拉取到该批次消息进行消费时，会先将整批消息拉取下来存在消费者客户端
对应的容器中，然后根据消费者实际的消费方式(单条或者批量消费)进行ConsumerRecord的传递。在位移提交时
也是按照实际消费的数据进行提交，并不以存储的颗粒度进行提交。
假设topic-1 上面 1001 - 1100 这一百条消息是按照批进行存储的，那么实际拉取下来就是100条消息存在客户端缓存中，
若消费者是单条的方式进行消费，那么它每消费一条就进行一次offset 提交，而不是消费完所有100条再一次性进行offset提交。

压缩消息相对批量消息多了一个解压缩的过程，其它情况类似。


2. Kafka 有哪些情况会导致消息丢失?  哪些情况下消息会重复? 如何避免?

消息丢失:
①：消息生产者配置的acks = 0 或者 1,然后当某个分区leader节点故障后，如果此时消息还未被消费，并且follower也
	未同步到该消息（ISR中只有leader,没有其它follower）,新选举出来的follower就会因为从更小的offset开始记录，
	这时就导致了消息的丢失
②: 分区副本数为1, kafka默认日志刷盘是考操作系统取完成的，这样若某个分区的leader节点故障，同时消息未被刷盘的话，
	消息就会因为掉电而丢失
③: 消费者在消费消息时选择的自动提交，而不是手动提交。这样消费逻辑的执行出现异常，就会出现消费位移已经提交，但是部分逻辑执行失败
	这样对于失败的那部分逻辑而言消息是丢失了的。其实只要把消费接口做成幂等的，并且使用手提位移提交的方式就可以避免消费端的消息丢失。
以上消息丢失只需要对响应的配置做出修改即可


消息重复:
①: 生产者重复发送了消息，对于kafka而言这些消息是不一样的，但是业务角度来看都是相同的数据。
②: 消费者进行批量消费，消费到一半时出现异常，选择的手动提交消费位移，当消费者重新批量消费时已消费过的部分属于重复消费。
消息重复的情况只需要做好消费接口的幂等性设计即可。



3. Kafka 如何实现消息的顺序消费?

kafka 分区间不保证消息的顺序性，若需要对多分区进行消费同时还需要保证消息的顺序，是需要将消息拉取
下来做排序处理，之后再执行消费动作。该做法一方面效率较低，实现复杂，还面临消费位移提交的麻烦。
若条件允许可以通过以下两种消费方式实现顺序消费:
① 需要顺序消费的消息由单个生产者发送:
	单生产者发送的所有消息，在发送时就是按照顺序进行的，这时broker端指定分区leader在存储消息时也是顺序存储
    这时对应的消费者在消费时也是顺序的。这就是顺序消费了，这里关键的环节就是让这个生产者发送的消息都存储到
    一个分区中，通过相同的key 就能做到这种效果。

② 需要顺序消费的消息由多个生产者发送:
	多个生产者发送指定相同的key也可以将消息发送到同一个分区，但是多个生产者发送时消息的发送顺序和消息的存储顺序
	并不能做到一致，也就是说即使消息存储在了同一个分区，这里面的消息也是不保证有序的。
	这时就需要确保业务上的有序，可以考在消息体内增加序列号字段，选择足够大的消费批次，然后对不同key分区，对每组消息
	检查序列号是否完备，完备的进行消费，并计算出可提交的最大位移(没有间断)进行提交，同时做好消息的去重处理。




4. Kafka 消费端位移提交是如何存储的？具体工作机制是？
Kafka 消费位移提交到服务端存储在 __consumer_offset 的内部topic中, 位移以<GroupId, Topic, PartitionId> 作为key
以实际消费位移大小作为value(还包括其它信息)，存储在 __consumer_offset topic中的某一个分区中。当消费组内消费者出现
上线或者下线或者消费者重启时会从该内部topic下通过 key 获取 GroupId, Topic, PartitionId 指定的位移地址，然后再从log中找出该消息进行消费。



5. Kafka 消息的存储格式?
kafka消息存储分V0,V1和V2版本 三个不同的日志存储格式，Kafka版本对应日志格式版本的关系如下:
Kafka 0.10 以前: V0 版本日志
Kafka 0.10-0.11: V1 版本日志
Kafka 0.11 以后: V2 版本日志

kafka 消息按照 topic 进行划分，每个topic 下以分区进行细分，每个分区独立保存各自的数据(使用独立的offset)
分区为了保证高可用一般都会创建多个副本，多个副本按照一个leader 多个follower进行分工，leader直接对接生产者和
消费者，follower从leader同步数据做好数据的备份。 不论leader还是follower 都会将数据持久化到磁盘log文件，
实际log 文件在物理形式上一个文件夹，下面分多个segment,每个segment主要包含存储消息的.log 文件，.index稀疏索引
文件 和 .timeindex 时间索引文件。 这些文件以当前分区消息存储的offset 作为文件名。
其中log文件中存储的完整消息在 v2 版本中是以 batch 形式存储的。这里不展开具体格式，只做大致描述
(1) 生产者发送的ProducerBatch 对应在broker端为 RecordBatch ,批量发送过来的消息存储上也是批量存储
(2) 实际存储时每批消息数据在拉取时会被一次性拉取给到消费者,由消费者客户端进行批次内操作
(3) 压缩消息也是直接存储压缩后的消息,实际消息的解压缩处理交由消费者客户端完成



6. Kafka集群中Controller负责哪些工作?



7. Kafka 服务端幂等和事务指的是什么？如何使用?




8. Kafka 生产者客户端消息的发送流程?如何确保发送成功?
Kafka生产者发送消息时，KafkaProducer 在调用send 方法发送消息时，是采用的异步发送的方式，实际发送过程是通过
main 线程 和 Kafka 客户端的 sender 线程协同工作完成的
具体过程如下：
(1) KafkaProducer 调用完send 方法后，消息会依次经过 拦截器,序列化器 和 分区器处理
(2) 然后消息会进入Kafka 客户端的 RecordAccumulator 中做一个缓冲，该缓冲池默认 32M, 里面将待发送的消息根据
    分区保存到对应的双端队列 DQueue 中
(3) RecordAccumulator 中的DQueue 实际存储的元素是 ProducerBatch, send 方法默认发送的是ProducerRecord
    因此在RecordAccumulator 中会将 ProducerRecord 封装成ProducerBatch 进行批量发送，这个可以根据batch.size
    参数进行设置，默认是16K.
(4) 若DQueue 中的消息同时满足等待时间大于 linger.ms时，sender线程就会将DQueue 的ProducerBatch 消息拉取出
    封装中broker - List<ProducerRequest> 形式，并存入 InFlightRequests 队列中
(5) sender线程使用 InFlightRequests 来保存正在发送请求，因为实际发送时存在消息发送给了broker，但是broker并没有
    响应结果。这时Kafka 为了不阻塞发送过程，设置了默认可以通知支持 5 个请求在发送，若这5个请求都没有发送完成，则后面的
    请求就阻塞不再执行。
(6) 当接收到broker响应，消息发送成功时 sender线程会清理掉 InFlightRequest 和 DQueue中的数据并继续向 RecordAccumulator
    取数继续发送。

(7) 若KafkaProducer 发送消息上使用的事同步或者带回调的形式，那么消息发送成功后还会进一步的更新Future 或者执行 CallBack中的方法
(8) sender线程消息发送失败, 则会更具 retries 配置进行重试。

要想确保消息发送成功，一般有以下方式做确保
-> 使用同步的方式进行发送,send 之后继续调用get() 等待结果返回; 这种方式的缺点是会一直阻塞客户端代码 不推荐
-> 发送是设置CallBack 回调, 在执行的方法里进行判断，若发送失败则继续发送; - 推荐
-> 还是使用异步发送方式,同时增大 retries 重试次数(如 Integer.MAX_VALUE), 让sender线程进行大量的重试
   对于一般的网络抖动或者分区leader 导致的发送失败，这种做法可以做到一定程度的确保  -推荐





################################################ 二 MySQL (熟练掌握) ###########################################
1. 聊一聊 MySQL的索引？
什么是索引? InnoDB 索引的数据结构是怎样的? B+树和B树有哪些区别? 索引有哪些类型? 怎么应用索引?
MySQL 中的索引是一种用来提升查询性能的数据结构。
存储引擎InnoDB 中的索引是以B+树的形式来组织的。索引的结构表现为
(1) 使用数据页作为树的节点，每个页大小默认为16KB
(2) 以聚簇索引为例，索引树中的非叶子节点存储主键的值，叶子节点存储完整的记录
(3) 叶子节点同一页中的记录按照主键的递增顺序存储,前1条记录指针指向后一条记录
(4) 非叶子节点中,同一页中保存按照主键递增的记录项，按照主键值和子节点页块的对应关系
    并且主键值取的对应页块中的最小值
(5) 每个数据页不论叶子节点还是非叶子节点都维护了各自的页目录，这样当通过主键来查询时，可以通过快速的二分查找定位
    数据处在当前页的什么位置? 然后逐级的向下比较，若查询条件的值介于[m,n) m,n在目录页中相邻，则继续找出m对应的页
    依次查找直到叶子节点。
(6) 由于数据页作为非叶子节点可以存储上千个目录项，因此即使当表中有上亿条记录，B+树也仅需要4级的高度，这意味着在一亿条
    数据中筛选出目标也只需要发起4次磁盘IO,大大提升了查询效率。

B+树 和 B树的区别:
(1) B树是一种多分叉平衡查找树，B+树更类似于将链表节点改成数据页的跳表
(2) B树所有节点都保存数据，要想获取全量数据，需要汇总B树所有叶子和非叶子节点
    B+树种叶子节点保存了全量的数据,所有非叶子节点更像是这些叶子节点的索引
(3) B树中在父节点的值的间隙中才有指针指向子节点,假设有10,20 两个值，那么对应可能会有3个子节点
    B+树种父节点的目录项指向子节点, 若父节点中有 10，20两个目录项，那么该节点下只有2个子节点
(4) 查找B树时数据可能在非叶子节点中找到，而对于B+树不管是聚簇索引还是二级索引，数据最终都要查到叶子节点上



若某张表的数据特别大，超出了页大小的容量限制，数据是如何存储的?
若叶子节点页每页只能存储一条记录，那么B+数的叶子节点就退化成了链表，类似的B+树就退化成了跳跃表。
为了避免这种情况发生，需要每个页至少保存两条记录。这样就要求每条记录的大小不超过 8K .
那么当记录大小超过8K的话，数据该如何存储呢？
InnoDB 数据页中数据行的存储具有不同的行格式
(1) 如果是compact 的行格式 就将该记录的前768个字节保存在叶子节点中，然后将剩下的部分保存在另一个新开的页中，
通过定义额外的指针指向该新开的指针来访问完整的数据。
(2) 如果是dynamic 的行格式，实际的行数据全部保存在新开的几个页中,数据页只会保存指向保存数据新开页的指针。

MySQL 5.7 及8.0 开始，InnoDB 默认的行格式该成了 Dynamic, 因此当数据页中行溢出时，数据的存储是以以上(2)的方式进行的
若表定义中不可避免存在大字段,那么可以考虑使用 MyISAM存储引擎,因为MyISAM记录数据与索引数据在存储是上分离的，因此不会出现行溢出
此外还可以增大page_size 的大小(修改源代码的方式)为32K或者64K


索引的类型可以按照不同维度来分类
(1)逻辑上来看
索引可以分为: 普通索引,唯一索引,主键索引等
(2)按照作用字段数量来看
可以分为: 单列索引 和 联合索引
(3)按照物理存储方式上来看
可以分为: 聚簇索引和二级索引


索引的应用(SQL调优):
(1) 索引的设计原则
频繁用作where查询条件的字段
经常被order by 或者 group by 的字段
distinct 的字段创建索引
varchar 类型的字段创建索引指定长度(使用字符串前缀来创建) order by 可能不准
创建联合索引,使用频率更高的字段放在最左边
优先使用区分度高的字段创建索引(使用频率差不多的情况下)
多个字段需要创建索引段的情况下,联合索引优于单值索引

经常更新的字段不要创建索引
无序的值不建议创建索引

(2) 索引失效注意事项










2. 说一说MySQL的事务？
什么是事务? 有哪些特性? 特性是怎么实现的？事务如何做到隔离? RR隔离级别是如何实现的？


3. MySQL中有哪些锁?他们有什么用途?


4. MySQL中有哪些日志? 它们分别有什么用途?
mysql 中日志可以分为: 二进制日志, 错误日志, 通用查询日志,慢查询日志,重做日志 和 回滚日志。

二进制日志(binlog): 记录对表记录进行修改操作的日志，一般用于数据的主从同步，数据备份。
    binlog 有三种工作模式: 行模式,statement 模式 和 mixed 模式


错误日志: 记录mysql启动,运行，停止过程中出现的问题，方便我们了解服务器的状态。
通用查询日志: 记录用户所有的操作，包括建立连接，释放连接，执行的SQL指令等。
慢查询日志: 记录查过long_query_time 阈值的查询操作的日志.
重做日志: WAL机制下修改数据前先记录的日志，用于宕机后数据的恢复。
回滚日志: 回滚段中保存的日志，用于事务的回滚和MVCC机制的实现。



5. 比较一下存储引擎 InnoDB 和 MyISAM？
(1) InnoDB 支持外键，MyISAM 不支持
(2) InnoDB 支持事务，MyISAM 不支持事务
(3) 如果存在大量更新和删除时，InnoDB 效率更高
    如果存在大量的插入和查询, 那么MyISAM 效率更高
    (为什么?)
(4) InnoDB支持行锁, MyISAM仅支持表锁
(5) 由于不支持事务,崩溃后无法安全恢复
(6) MyISAM 节省资源,消耗少,业务简单；InnoDB 并发写，支持事务，资源消耗大



6. InnoDB底层存储结构?与B+树的关系？
InnoDB文件存储按照从记录到 .ibd 文件的顺序来看，具有如下关系:

记录行 ==> 数据页 ==> 区 ==> 段 ==> 表空间文件

-> 其中记录行就是包含用户表记录的数据,除了用户数据外还有 next record 指针, record type 等记录头信息
-> 数据页默认大小为 16K, 页作为数据与磁盘交互的基本单位，一个页会包含多条记录，页之间通过首尾指针连接，此外还维护者一些记录数量,页目录等信息
-> 为了让B+树种叶子几点逻辑上前后相邻的页在物理上也具有相邻的特性，以此来提高批量数据查询效率，
   InnoDB在页结构之上使用区来存储多个数据页，每个区中包含64个数据页，这样一次磁盘IO可将多个逻辑相邻的数据页加载内存
-> 段是InnoDB 组织数据的基本单位，例如表有数据段(叶子节点段),索引段(非叶子节点段),回滚段等，InnoDB中同一个表中所有的数据都存储在(8.0以后).ibd文件中
   因此InnoDB 需要通过搜索在.ibd 文件中搜索段才能找到对应的数据或者索引，这样直接定位可以减少在同一个文件中搜索的范围。(不考虑碎片区的情况)
-> 表空间文件也就是 .ibd 文件，是InnoDB 数据存储的文件,数据的落盘处理就是落到该文件

B+树中不论叶子节点还是非叶子节点都是以数据页的形式组织的，当内存中B+树的节点发生修改后需要落盘时，是将通过对应的节点找到它在
.ibd 文件中的段，然后找到它在段中的某个区，在区中定位出对应的数据页，最后将数据写入进去。


7. InnoDB 中存在哪些行锁,分别在什么场景下使用?
记录锁: 对记录以共享锁和互斥锁规则进行加锁，锁住的是实际存在的记录
间隙锁: 当对不存在的记录进行加锁(共享锁或者互斥锁)，会锁住该不存在记录所在的间隙，这时在该间隙内进行记录的插入时会被阻塞
临键锁: next-key lock,相当于记录锁+间隙锁，表现为当对某个范围进行加锁时，范围内存在的记录会使用记录锁进行加锁处理，范围内不存在记录的间隙则使用间隙锁加锁
       这时其它事务既不能对记录进行修改，也不能在间隙内插入数据。
插入意向锁: 当有事务对某个范围加上了间隙锁，这时如果有多个事务想在该间隙内插入记录，显然这几个事务的插入操作都会被加锁阻塞，但是他们在被阻塞时
       相互之间还是可能会出现插入重复主键的情况，插入意向锁就是用来在他们之间进一步加锁避免重复插入的锁。



############################################# 三 Redis (熟练原理&灵活应用) #########################################
1. Redis 有哪些数据结构? 它们底层是如何实现的？(Hash,Zset)

2. Redis 是单线程的为什么还这么快?
(1) 基于内存操作，CPU访问内存的速度是微秒，甚至100ns 的级别; 这是能快起来的基础
(2) 但是当大量并发请求进来之后，redis 还能保持让每一个请求快速得到响应，就需要用到IO多用复用技术
    redis 线程模型使用linux底层的epoll 多路复用技术，并在线程模型上采用reactor 模型，具体表现为
    ① 客户端并发通过socket向server发送请求指令时，IO多路复用器批量的读取文件描述符
    ② IO多路复用器将获取到的文件描述符添加到队列中
    ③ 文件事件分派器从队列中读取需要处理的文件描述符，根据不同事件类型给到对应的处理器
    ④ 事件处理器可以分为 命令应答处理器,命令请求处理器和命令响应处理器，当判断是 k-v 读取操作时
       文件事件处理器就将它给到 命令请求处理器，由命令请求处理器执行对应操作
    ⑤ 命令请求处理器执行完对应操作时通知响应处理器由响应处理器返回结果

    可以看到redis线程模型下存在明确的分工合作，只要用户指令不阻塞，确保在内存下可以快速执行，整个过程
    也是可以迅速执行完的。

(3) 单线程快速处理,避免了线程之间的竞争(程序在用户态和内核态的上下文切换)


3. Redis 如何保证数据不丢失? 若是集群模式下如何保证?
I、非高可用情况下保证: 数据持久化(牺牲可用性保证可靠性)
Redis数据持久化有哪些方案? 两种持久化方案的工作机制? 数据如何刷盘?

II、高可用情况下保证: 集群节点故障后如何处理保证数据不丢失


4. 介绍一下Redis 集群?
Redis有哪些工作模式? 集群模式与主从模式的关系? 集群槽位划分(节点上下线)? 主从之间数据同步方式?
为什么Redis集群数据同步没有采用Kafka集群的acks=all的方式?




################################################ 四 分布式组件 (事务和锁) ###########################################
1. 分布式锁用redis 或 zookeeper分别怎么实现?


2. 分布式事务两阶段提交？TCC实现分布式事务的原理? Seata分布式事务的原理及注意事项?



################################################ 五 JDK (并发&JVM&集合) ###########################################

1. JVM 如何有如何判断对象是否存活？有哪些垃圾收集算法？对应的又是哪些垃圾收集器?
JVM 判断对象是否存活主要 有引用计数法 和 可达性分析法 两种方法。
由于引用计数法存在循环引用的问题，因此JVM 虚拟机hotspot 采用的是可达性分析法。
可达性分析法，简单而言就是 通过设定一些GC Root, 从这些Root 出发遍历所有的树形引用
若对象没有出现在引用树上，就认为是可回收对象。常见的GC Root 有
a) 方法栈中的引用型变量
b）类静态属性及常量
c) 本地方法栈中的应用型变量
d) 虚拟机内部Class对象
e) 被同步锁持有的对象

JVM对垃圾收集采用分代收集的方式，用到的垃圾收集算法有
(1) 标记-清除法: 标记清除法采用先标记垃圾，然后将垃圾清除掉的方式回收
    它的问题在于标记阶段可能需要标记大量的垃圾，这样标记过程可能会存在性能问题，从而导致标记时性能不稳定
    另外再清除阶段，将垃圾清除后造成了堆区空间的不连续
(2) 标记-复制法:将内存划分区域,一部分使用，另一部分空闲，每次在使用的区域内将存活对象标记下来，然后将它们复制到空闲区域
    标记复制法在当存在大量朝生夕灭的对象时，可以只复制一小部分，并且由于使用复制的方式，回收垃圾的同时
    还保证了回收后区域的连续性。
    这种回收算法的问题在于，如果对象大多数都是存活的，需要复制的对象就会特别多，会存在严重的性能问题。
(3) 标记-整理法: 标记整理法也是先标记，然后将对象这里到内存区域的连续区域，整理完之后可回收对象被清理同时也没有内存区域的间断。
    标记整理法同样也存在性能问题,如需要回收区域的对象大多数都是存活的，在整理时也需要移动大量的存活对象，相较于标记复制的好处是
    不需要预留一部分空闲的内存空间。

常用的垃圾收集器，及搭配使用组合
标记-复制:
    标记复制算法主要用于新生代的垃圾回收,包括 Serial, ParNew,Parallel Scavenge 收集器都是使用的复制算法
    其中 Serial 是单线程进行回收, ParNew 是使用多线程进行回收 而 Parallel Scavenge 则是一款专注于吞吐量的垃圾收集器，
    譬如对于计算密集型的应用，更多的是希望譬如100s 内更多的时间花在计算上。前面的 Serial,ParNew 都是专注于停顿时间，则是IO密集型需要的
    同时 Parallel Scavenge区别于其它新生代垃圾收集器的一个重要特征是 它提供了自适应的细节参数，这就省去了研发人员的参数配置过程

标记-清除:
    CMS垃圾收集器是 Concurrent Mark Sweep 并发标记清除的首字母简称，也是经典垃圾收集器中唯一一个使用标记清除算法的收集器。
    它用于老年代的垃圾收集。CMS也是一款跨时代的垃圾收集器，区别之处在于它不需要stop the world 而是可以和用户线程一起运行并发的
    执行垃圾收集(并发标记&并发清除)。
    CMS垃圾收集器存在以下两个主要问题
    (a) 会存在浮动垃圾: 垃圾标记和清除过程都是并发完成的，在清除过程中是会出现新的垃圾，这就要求触发垃圾清除的老年代使用率不能
    是100% 而要比这个小, 譬如70%, 剩下的30% 用于GC时存放新产生的老年代对象。
    (b) 会存在碎片问题: CMS 使用的是标记清除算法,标记清除算法由于清除后造成了堆区内存的不连续,因此多次GC之后会看到
    老年代明明还有空间，但是就是不能被使用，就是因为大对象需要的连续空间不够。CMS提供了 CMSFullGCsBeforeCompaction参数来进行
    空间的整理，利用该参数可以设置每隔多少次Full GC 执行一次内存空间的压缩整理。

标记-整理:
    标记整理算法一般用在老年代的垃圾收集上，使用该算的垃圾收集器有 Serial Old 和 Parallel Old.
    Serial Old 是 Serial 的老年代版本。而 Parallel Old 则是 Parallel Scavenge 的老年代版本。



2. 线上出现OOM问题，该如何进行问题定位?
OOM内存溢出按照不同维度划分可能有不同的情况 按照OOM报错内存分类可能有 栈区内存不够,堆区内存溢出,元空间内存溢出
按照业务的角度可能有: 代码中对大块数据进行处理(如查询不分页),连接服务端不释放连接导致连接占用大量内存等

下面主要从内存分类的角度来分析内存溢出的可能情况并给出一般化的定位方式
(1)栈区内存不够:
报错-> java.lang.OutOfMemoryError: java.lang.StackOverflowError
栈区内存溢出，跟栈空间总大小及每个线程栈最的空间大小有关；栈的总空间大小跟系统有关，不可设置。但是每个线程栈帧的大小
可以通过参数 -Xss 设置，-Xss设置的越大可以启动线程数就约多。
此外 如果某个线程内使用递归调用，递归嵌套数量太大也会导致 StackOverflowError。
因此 总结来看可以通过 -Xss参数设置 和 递归代码改造来解决栈区内存不够的问题。

定位方式:
总线程数太多导致栈空间不够分配给线程:
线程栈总可用内存 = JVM进程占用内存 -（-Xmx的值）- （-XX:MaxPermSize的值）- 程序计数器占用的内存
通过 jinfo 指令可以查看到 VM的参数配置，利用 top pid 可以查看到当前有多少个线程，然后通过上述公式
可以计算出总栈空间大小SS, SS - 线程数 * Xss 配置的栈大小 得到的结果是否特别小或者接近0, 如果是这样说明栈的总空间偏小
或者需要起更多节点来应对并发。

方法递归调用嵌套太多导致线程栈溢出:
异常栈信息中存在大量同名嵌套，这种情况就属于当个线程栈的栈空间溢出。

(2)堆区内存溢出:
报错-> java.lang.OutOfMemoryError:Java heap space
堆内存溢出可能的情况有:内存分配空间太小,内存泄露等
> 对于内存分配空间大小问题,刻意通过jinfo查看, 修改配置后可以解决

> 而对于内存泄露可以通过jmap -histo:live pid | more 指令查看按各类对象大小倒序排序的
  可以看到哪些对象占用的对空间明显较多，若对象是自定义的类对象可以再代码中review 找出问题代码。
  若非自定义代码可以


(3)元空间内存溢出:
报错-> java.lang.OutOfMemoryError: PermGen space
元空间一般不参与垃圾回收, 这部分内存溢出需要考虑是否是代码中使用了大量的反射等处理


3. 类加载过程?什么是双亲委派制?为什么使用双亲委派?





################################################ 六 系统设计(项目&临时设计) #########################################
1. 并发系统设计? 发红包/活动秒杀 等。
   活动商品秒杀:
   (1) 使用Redis 存储商品信息,redis先扣减，扣减成功后使用MQ异步保存用户-订单-商品信息
   (2) 使用 watch 乐观锁机制配合管道+事务完成批量指令的发送和执行
   (3) 当watch 的k-v 发生变更, 管道指令在执行时会返回NULL,若执行失败,返回的结果列表为空
       通过对 pipeline.execute() 的放回结果进行判断，可知当前执行执行有没有获取到锁，是否执行成功
   (4) MQ消费端消费生成 用户-订单-商品 的抢购记录(如何确保消息不丢失?)
   (5) 用户抢购之后抢断保存状态,首次查询未获取到数据提示重试,首次查询到之后缓存订单数据,之后每次查看不再走后端请求


   分抢十亿红包(金额随机,不能重复领取):


2. 功能系统设计? 如网站上看到的评论,弹幕,访问记录,分类排序等。


############################################## 七 其它 (网络,系统,Maven,Git) ######################################
1. 系统进程间通信有哪些方式? 优缺点分别是什么？什么场景下使用?
进程使用的是虚拟内存地址，无亲缘关系的进程的内存空间是相互独立的，因此进程间需要通信，需要依赖内核支持。
操作系统内核提供了如下六种进程间通信方式:

(1)管道: 内核提供的一串单向通信的缓存，分为匿名管道和命名管道
        匿名管道只能单向通信，且只能在有亲缘关系的进程间进行通信，譬如父子进程，或者由同一进程创建的两个子进程
        如shell 脚本中执行 "cat aaa.txt | grep 123", 实际上使用的就是由于shell 进程创建了两个进程 "cat" 和 "grep"
        由于两个子进程在创建时可以由父进程指定管道，因此匿名管道的对应的缓存(文件描述符) 对于两个进程都是可见的。

        对于命名管道,指的是在使用前先创建相应的管道名，在使用时由于有对应的管道名可以指定，因此创建两个命名管道就能实现
        双向通信。 命名管道在shell 脚本中的使用如下:
        $mkfifo pipe1
        $echo aaa.txt > pipe1
        $cat pipe1
        以上"echo"删除数据到pipe1之后，会一直阻塞直到后续"cat"指令执行完才能结束运行。

        不管是匿名管道还是命名管道，进程写入的数据都是缓存在系统内核中，另一个进程读取时也是需要从内核进行读取，通信数据遵循
        先进先出的特点。

        缺点: 通信双方需要同步进行，读取进程没有结束，写入进程需要一直阻塞; 通信进程需要具有亲缘关系
        优点: 足够简单；管道生命周期同创建进程

(2)消息队列: 前面提到的管道实现进程间通信是同步的进行的，消息队列也是先进先出的通信方式，但是消息队列是异步的。
            消息队列的收发双方指定了消息的格式后。写进程将消息写入后可以继续往后执行，读取进程读取消息后，内核才会删除
            消息数据。

        优点: 可以按照自定义格式发送数据，避免了管道的字节流传输问题
        缺点: 消息大小受限(系统有限制);需要在用户态和内核态来回拷贝数据相对效率不高;
             消息生命周期跟随系统，进程异常终止将占用内核空间。


(3)共享内存: linux系统中进程使用的虚拟内存空间，因此进程间在虚拟内存空间中的数据相互隔离和独立；使用共享内存可以将同一块内存区域
            映射到多个进程的虚拟空间，这样进程就可以通过在共享内存区域数据的读写来实现通信了。

        优点: 避免了数据在用户态和内核态之间的拷贝
        缺点: 存在并发读写的问题，需要借助同步工具避免出现脏数据

(4)信号量: 信号量更多的是一个进程同步工具，不同进程通过使用信号量来进项共享资源的访问，通过设定不同的信号量值
            可以实现进程间的同步操作和互斥访问(类似与锁)。

        缺点: 不能直接通信，一般配合共享内存使用

(5)信号: 前面讲的都是进程间正常的通信机制，信号则是用于进程间异常中断处理，可以直接在用户进行和内核之间发送。
        信号可以进一步分为 硬件触发 和 软件触发； 硬件触发譬如键盘操作  Ctr+c , Ctr+z,都会给前台运行的进程发送对应的信号，
        进程响应后终止执行或者撤销效应执行。
        软件触发 譬如可以通过 "kill -信号值  PID" 方式进行通知

        优点: 可以异步的进行通信，信号啥时候都可以发送给目标进程
        缺点: 只能用于异常情况

(6)套接字通信: 套接字通信是进程间通信中唯一可以跨主机进行通信的，当然如果在同一主机也可以使用套接字进行通信。
        套接字通信方式可以分为三种:
        ① UDP 面向 IP+端口的无连接通信, 发送完后不管对方是否接收到
        ② TCP 面向 IP+端口的连接通信，通信前需要在两个主机之间通过三次握手建立连接， TCP连接是基于四元组的
           连接通信可能存在连接释放未完成，端口号被占用的情况
        ③ 套接字本地通信，


2. Nginx 实现网关功能参数?



############################################## 八 Spring Cloud 组件 ############################################
1. sentinel 有哪些功能? 它的工作原理是怎么样的?
sentinel 可以提供限流,降级 和 熔断等功能。
sentinel 限流使用的是一种近似的 滑动时间窗算法，具体来讲  它在时间窗内划分多个样本窗，然后以样本窗为统计请求次数的最小时间粒度，否则
滑动时间窗将面临大量的重复统计。 假设一个时间窗被分隔成为 N 个样本窗, 那么当某次请求进来时,会将该请求进来时间落在样本窗统计值+1，然后判断
当前样本窗和之前统计的N-1 个样本窗 所有统计值加起来是否超过了阈值，若超过则阻塞请求。



2. nacos 注册中心工作原理? 它和eureka, zookeeper 的区别?
zk 区别于nacos和 eureka在于，zk定位是一个分布式协调框架，它只提供了简单的k-v
存储，时间通知 等功能。 而nacos 和 eureka 的注册中心的功能专门就是为服务注册与发现开发的。
此外对于注册中心而言，nacos 和 eureka 都能支持分布式理论的 AP, 而zookeeper 由于设计实现时是基于ZAB协议，
因此实际满足的是CP, 这样当zk在leader选举或者集群出现脑裂时zk将变得无法访问，这将影响到微服务的可用性。
作为注册中心而言，及时注册服务不是最新的也有必要返回给到服务进行调用。

eureka 和 nacos 的区别
(1) eureka注册中心是去中心化的集群，当某个节点挂了后不影响其它节点提供服务，集群中每个节点的都会同步获取其它节点的数据
    这为服务的可用心带来了较大便利。
    而 nacos使用的是主从模式。

(2) nacos 支持AP和CP两种模式，默认情况(服务注册为临时节点)是AP模式。 eureka只支持AP模式
(3) eureka开源社区已经不再更新(进入了维护模式)，而nacos开源社区则较为活跃





3. 比较一下 paxos, zab 和 raft协议之间的区别?
paxos协议(basic paxos) 算法描述:
算法中存在三种角色:
a) 提案节点 Proposer: 负责向集群中发起提案
c) 决策节点 Acceptor: 负责对提案进行决策和审批
d) 记录节点 Learner: 记录所有已经通过了决策的审批，如网络分区出现后少数派需要跟上多数派时，
                    这时的少数派就是记录节点

算法可以分为两个阶段
阶段一:
proposer 向Acceptor 发送编号为N的提案 作为 prepare请求
Acceptor 判断提案之前是否接受到过编号大于N的提案
    若没有接收到比N更大的提案,则向同意该提案，并返回之前接收到的最大的提案内容 maxValue作为返回
    若之前接收到过比N更大的提案,则直接忽略该编号为N的提案

阶段二:
Proposer 接收到来自Acceptor 集合中过半数的 Acceptor 响应就会将提案N以及之前收到的maxValue作为value 一起组成二元组(N,maxValue)作为
        Accept 请求发送给到Acceptor
Acceptor 接收到编号为N的Accept请求，只要该Acceptor还未对编号大于N的prepare做出过响应，就通过该提案,并记录下来



ZAB 协议(Zookeeper Atomic Broadcast):
由于 ZAB协议也是基于Multi Paxos 协议，因此ZAB 协议的主要内容也是针对的如何解决以下三个问题
(1) Leader 如何选举
(2) 数据如何同步
(3) 如何保证安全

这里主要讲一讲前两点
1.Leader 如何选举(Zookeeper 的Leader选举机制)
Zookeeper 节点有三种可能的状态
leading: 作为leader 节点时处于该状态，接受客户端更新，写入本地日志并复制到从节点
following: 作为follower节点处于该状态, 接受主节点的更新并写入本地日志
looking: 处于选主状态，不对外提供服务，直至选主结束

选举的基本规则:
节点B接收到节点A发起的选举请求后，B在判断是否需要给A投票时，需要做如下判断
-> B的纪元是否小于A的纪元
-> B的zxid 是否小于A的 zxid
-> B的 sid 是否小于A的 sid
以上条件当前一个满足之后可以不用满足后面的，基于以上规则的选举流程如下
(1) 处于Looking 状态的节点向其它节点发送选举请求
(2) 其它节点(可能是Looking状态，也有可能是following状态) 接收到请求后根据选举规则进行判断
    并将投票结果广播给所有节点
(3) 竞选节点统计投票结果，判断同意的投票数是否过半，若过半则更新自己的状态为leading 并向其它节点发送心跳
(4) 竞选失败节点(票数未过半)，若接收到其它节点并且同意该节点作为leader 也会将自己的状态置为 following
    若没有同意其它节点时 会再次发起投票请求。


2.Zookeeper Leader 和 Follower 之间如何同步数据?
同步数据的大致过程如下
1) leader 接收到客户端请求后，将请求转化为一个proposal，同时为每个proposal分配一个zxid
2) leader 为每个follower 分配了一个单独的队列，每次请求过来都将proposal 发到队列中
   follower都是通过队列中取数来获取消息，确保了顺序性同时还解耦了数据发送过程
3）follower 接收到数据后，会先将数据以日志形式写入本地磁盘，写入成功之后给leader一个ack反馈
4) leader接收到超过半数的ack响应后，即认为消息发送成功
5) leader判断消息发送成功后，就开始广播当期zxid 的消息的commit通知。follower收到commit 通知后
    会将对应的消息进行提交。

Raft 协议基本与ZAB 协议相同，这里不再赘述。
有些名词的叫法不同,如 epoch 和 term的区别，此外同步数据方式上zab是从节点从主节点拉，Raft是主节点推送给从节点。
具体可以参考语雀: https://www.yuque.com/minsky-r5fqc/ga1bfa/cqv42g

############################################## 九 开发中常见难点问题 ######################################################
1. 性能调优问题
(1) DB查询调优
    分页查询如何避免页数很大时查询慢的问题？
    一般而言可以从以下几方面考虑来做查询优化:


遇到单次查询数据量很大时，该如何解决性能问题?
    代码层面可以采用并发方式对该批次数据进行分页查询，当所有页都查询出来后再汇总成完成数据返回，这样做可以一定程度提高查询效率。
    如果数据量在limit分页页数很靠后，可以进一步考虑在查询时引入覆盖索引，使用子查询先查询主键索引，然后再通过外层查询使用主键索引
    做进一步分页。


(2) JVM参数调优


(3) 应用容器调优(Tomcat调优)


2. 数据一致性(DB&缓存一致性,分布式一致性)
(1) 如何保证数据库与缓存之间的数据一致性?

(2) 分布式事务中如何保证数据的一致性?

(3) RocketMQ事务消息如何保证数据的一致性?




3. 技术选型比较问题？


4. 问题定位?
(1) 线上遇到OOM问题定位
(2) 线上遇到CPU使用率100%问题定位


5. 设计模式应用
用过哪些设计模式？分别是如何用来解决什么问题的？
(1) 模板方法模式 - 发送企微消息时使用
(2) 策略模式 - 不同商品类型对应不同捕获类型,配合责任链在一个接口中实现
(3) 责任链模式 - 将多个处理添加到处理链中(集合/链表),判断由哪一个处理,或者前面的处理完后面的继续处理。
(4) 代理模式 - 对被代理对象做一次包装(静态代理),实际使用时直接使用代理对象;
              利用反射机制动态的对被代理对象进行代理处理，使用时直接使用被代理对象

面向对象设计的大多设计模式都是依赖于 多态特性，基于该特性的不同组合就有了不同的设计模式。
此外设计上一般需要遵循一些设计原则:
(a) 单一职责原则 -- 模块需要尽可能保证职责的单一,便于功能的重用和维护
(b) 开闭原则  -- 对修改关闭,对扩展开发
(c) 里氏替换原则 -- 父类出现的地方可以使用子类来替换；子类可以实现更多的更功能，但是父类中出现的行为,子类也必须拥有;因此子类可以替换父类
(d) 接口隔离原则 -- 调用方不直接对被调用着的类进行调用，而是间接的通过使用接口来调用，让接口来屏蔽实现细节
(e) 依赖倒置原则 -- 依赖倒置描述的是在功能调用时,尽量调用一些抽象层次更高的接口或者抽象类，这样当需求出现变化时仅需要对抽象层进行扩展
                    修改配置即可。这种设计方式在逻辑顺序上，让实现类出现在了被调用之后，因此叫做依赖倒置。




########################
RestTemplate 调用超时问题该如何解决？
    -- 配置 RestTemplate 连接超时和读取超时时间，当出现超时时抛出超时异常
    -- 设置RestTemplate 连接池, 中参数配置:
            最大线程数: 200
            默认线程数: 10
            与服务器建立连接的超时时间: 1000ms 该超时时间需要小于等于使用方调用的超时时间(NG配置超时时间)
            从连接池获取连接的超时时间: 1000ms 连接占满,请求等待获取连接释放的时间
            服务器返回数据的时间: 1000ms 服务器返回数据的超时时间
            线程空闲时长: 10,000ms 连接线程空闲多长时间后进行释放

ES 与 MySQL 该如何比较?什么时候选用ES,什么时候选MySQL?ES相对MySQL有哪些优势?



RocketMQ工作原理?事务消息怎么使用?RocketMQ与Kafka如何做技术选型?
########################



############################################## 十 算法题  ######################################################

按照标签刷中等难度未做过的题:
数   组:[581,260,15,80,229]
链   表:[]
排   序:[]
动态规划:[]
哈 希 表:[]
   栈  :[]
队    列:[]
双 指 针:[]
滑动窗口:[]

字节高频题[1,3,739,34,103,165,198,200,236,240,415,232,470,287,215,206,239,300,234]
         [101,105,113,114,121,141,142,146,151,155,160,169,199,88,92,98]
         [5,15,20,21,23,25,34,41,42,46,53,54,69,79]



################################################ 一 Kafka(3.0) (精通) ################################################

1. Kafka 批量发送消息是如何存储的？批量消息是否需要批量消费? 压缩消息呢？
Kafka 批量发送或者压缩发送的消息都是按照发送过来的形式进行存储，并不做数据的解批或者解压缩处理.
由于存储就是按照批量进行的，消费者拉取到该批次消息进行消费时，会先将整批消息拉取下来存在消费者客户端
对应的容器中，然后根据消费者实际的消费方式(单条或者批量消费)进行ConsumerRecord的传递。在位移提交时
也是按照实际消费的数据进行提交，并不以存储的颗粒度进行提交。
假设topic-1 上面 1001 - 1100 这一百条消息是按照批进行存储的，那么实际拉取下来就是100条消息存在客户端缓存中，
若消费者是单条的方式进行消费，那么它每消费一条就进行一次offset 提交，而不是消费完所有100条再一次性进行offset提交。

压缩消息相对批量消息多了一个解压缩的过程，其它情况类似。


2. Kafka 有哪些情况会导致消息丢失?  哪些情况下消息会重复? 如何避免?

消息丢失:
①：消息生产者配置的acks = 0 或者 1,然后当某个分区leader节点故障后，如果此时消息还未被消费，并且follower也
	未同步到该消息（ISR中只有leader,没有其它follower）,新选举出来的follower就会因为从更小的offset开始记录，
	这时就导致了消息的丢失
②: 分区副本数为1, kafka默认日志刷盘是考操作系统取完成的，这样若某个分区的leader节点故障，同时消息未被刷盘的话，
	消息就会因为掉电而丢失
③: 消费者在消费消息时选择的自动提交，而不是手动提交。这样消费逻辑的执行出现异常，就会出现消费位移已经提交，但是部分逻辑执行失败
	这样对于失败的那部分逻辑而言消息是丢失了的。其实只要把消费接口做成幂等的，并且使用手提位移提交的方式就可以避免消费端的消息丢失。
以上消息丢失只需要对响应的配置做出修改即可


消息重复:
①: 生产者重复发送了消息，对于kafka而言这些消息是不一样的，但是业务角度来看都是相同的数据。
②: 消费者进行批量消费，消费到一半时出现异常，选择的手动提交消费位移，当消费者重新批量消费时已消费过的部分属于重复消费。
消息重复的情况只需要做好消费接口的幂等性设计即可。



3. Kafka 如何实现消息的顺序消费?

kafka 分区间不保证消息的顺序性，若需要对多分区进行消费同时还需要保证消息的顺序，是需要将消息拉取
下来做排序处理，之后再执行消费动作。该做法一方面效率较低，实现复杂，还面临消费位移提交的麻烦。
若条件允许可以通过以下两种消费方式实现顺序消费:
① 需要顺序消费的消息由单个生产者发送:
	单生产者发送的所有消息，在发送时就是按照顺序进行的，这时broker端指定分区leader在存储消息时也是顺序存储
    这时对应的消费者在消费时也是顺序的。这就是顺序消费了，这里关键的环节就是让这个生产者发送的消息都存储到
    一个分区中，通过相同的key 就能做到这种效果。

② 需要顺序消费的消息由多个生产者发送:
	多个生产者发送指定相同的key也可以将消息发送到同一个分区，但是多个生产者发送时消息的发送顺序和消息的存储顺序
	并不能做到一致，也就是说即使消息存储在了同一个分区，这里面的消息也是不保证有序的。
	这时就需要确保业务上的有序，可以考在消息体内增加序列号字段，选择足够大的消费批次，然后对不同key分区，对每组消息
	检查序列号是否完备，完备的进行消费，并计算出可提交的最大位移(没有间断)进行提交，同时做好消息的去重处理。




4. Kafka 消费端位移提交是如何存储的？具体工作机制是？
Kafka 消费位移提交到服务端存储在 __consumer_offset 的内部topic中, 位移以<GroupId, Topic, PartitionId> 作为key
以实际消费位移大小作为value(还包括其它信息)，存储在 __consumer_offset topic中的某一个分区中。当消费组内消费者出现
上线或者下线或者消费者重启时会从该内部topic下通过 key 获取 GroupId, Topic, PartitionId 指定的位移地址，然后再从log中找出该消息进行消费。



5. Kafka 消息的存储格式?
kafka消息存储分V0,V1和V2版本 三个不同的日志存储格式，Kafka版本对应日志格式版本的关系如下:
Kafka 0.10 以前: V0 版本日志
Kafka 0.10-0.11: V1 版本日志
Kafka 0.11 以后: V2 版本日志

kafka 消息按照 topic 进行划分，每个topic 下以分区进行细分，每个分区独立保存各自的数据(使用独立的offset)
分区为了保证高可用一般都会创建多个副本，多个副本按照一个leader 多个follower进行分工，leader直接对接生产者和
消费者，follower从leader同步数据做好数据的备份。 不论leader还是follower 都会将数据持久化到磁盘log文件，
实际log 文件在物理形式上一个文件夹，下面分多个segment,每个segment主要包含存储消息的.log 文件，.index稀疏索引
文件 和 .timeindex 时间索引文件。 这些文件以当前分区消息存储的offset 作为文件名。
其中log文件中存储的完整消息在 v2 版本中是以 batch 形式存储的。这里不展开具体格式，只做大致描述
(1) 生产者发送的ProducerBatch 对应在broker端为 RecordBatch ,批量发送过来的消息存储上也是批量存储
(2) 实际存储时每批消息数据在拉取时会被一次性拉取给到消费者,由消费者客户端进行批次内操作
(3) 压缩消息也是直接存储压缩后的消息,实际消息的解压缩处理交由消费者客户端完成



6. Kafka集群中Controller负责哪些工作?



7. Kafka 服务端幂等和事务指的是什么？如何使用?




8. Kafka 生产者客户端消息的发送流程?如何确保发送成功?
Kafka生产者发送消息时，KafkaProducer 在调用send 方法发送消息时，是采用的异步发送的方式，实际发送过程是通过
main 线程 和 Kafka 客户端的 sender 线程协同工作完成的
具体过程如下：
(1) KafkaProducer 调用完send 方法后，消息会依次经过 拦截器,序列化器 和 分区器处理
(2) 然后消息会进入Kafka 客户端的 RecordAccumulator 中做一个缓冲，该缓冲池默认 32M, 里面将待发送的消息根据
    分区保存到对应的双端队列 DQueue 中
(3) RecordAccumulator 中的DQueue 实际存储的元素是 ProducerBatch, send 方法默认发送的是ProducerRecord
    因此在RecordAccumulator 中会将 ProducerRecord 封装成ProducerBatch 进行批量发送，这个可以根据batch.size
    参数进行设置，默认是16K.
(4) 若DQueue 中的消息同时满足等待时间大于 linger.ms时，sender线程就会将DQueue 的ProducerBatch 消息拉取出
    封装中broker - List<ProducerRequest> 形式，并存入 InFlightRequests 队列中
(5) sender线程使用 InFlightRequests 来保存正在发送请求，因为实际发送时存在消息发送给了broker，但是broker并没有
    响应结果。这时Kafka 为了不阻塞发送过程，设置了默认可以通知支持 5 个请求在发送，若这5个请求都没有发送完成，则后面的
    请求就阻塞不再执行。
(6) 当接收到broker响应，消息发送成功时 sender线程会清理掉 InFlightRequest 和 DQueue中的数据并继续向 RecordAccumulator
    取数继续发送。

(7) 若KafkaProducer 发送消息上使用的事同步或者带回调的形式，那么消息发送成功后还会进一步的更新Future 或者执行 CallBack中的方法
(8) sender线程消息发送失败, 则会更具 retries 配置进行重试。

要想确保消息发送成功，一般有以下方式做确保
-> 使用同步的方式进行发送,send 之后继续调用get() 等待结果返回; 这种方式的缺点是会一直阻塞客户端代码 不推荐
-> 发送是设置CallBack 回调, 在执行的方法里进行判断，若发送失败则继续发送; - 推荐
-> 还是使用异步发送方式,同时增大 retries 重试次数(如 Integer.MAX_VALUE), 让sender线程进行大量的重试
   对于一般的网络抖动或者分区leader 导致的发送失败，这种做法可以做到一定程度的确保  -推荐





################################################ 二 MySQL (熟练掌握) ###########################################
1. 聊一聊 MySQL的索引？
什么是索引? InnoDB 索引的数据结构是怎样的? B+树和B树有哪些区别? 索引有哪些类型? 怎么应用索引?
MySQL 中的索引是一种用来提升查询性能的数据结构。
存储引擎InnoDB 中的索引是以B+树的形式来组织的。索引的结构表现为
(1) 使用数据页作为树的节点，每个页大小默认为16KB
(2) 以聚簇索引为例，索引树中的非叶子节点存储主键的值，叶子节点存储完整的记录
(3) 叶子节点同一页中的记录按照主键的递增顺序存储,前1条记录指针指向后一条记录
(4) 非叶子节点中,同一页中保存按照主键递增的记录项，按照主键值和子节点页块的对应关系
    并且主键值取的对应页块中的最小值
(5) 每个数据页不论叶子节点还是非叶子节点都维护了各自的页目录，这样当通过主键来查询时，可以通过快速的二分查找定位
    数据处在当前页的什么位置? 然后逐级的向下比较，若查询条件的值介于[m,n) m,n在目录页中相邻，则继续找出m对应的页
    依次查找直到叶子节点。
(6) 由于数据页作为非叶子节点可以存储上千个目录项，因此即使当表中有上亿条记录，B+树也仅需要4级的高度，这意味着在一亿条
    数据中筛选出目标也只需要发起4次磁盘IO,大大提升了查询效率。

B+树 和 B树的区别:
(1) B树是一种多分叉平衡查找树，B+树更类似于将链表节点改成数据页的跳表
(2) B树所有节点都保存数据，要想获取全量数据，需要汇总B树所有叶子和非叶子节点
    B+树种叶子节点保存了全量的数据,所有非叶子节点更像是这些叶子节点的索引
(3) B树中在父节点的值的间隙中才有指针指向子节点,假设有10,20 两个值，那么对应可能会有3个子节点
    B+树种父节点的目录项指向子节点, 若父节点中有 10，20两个目录项，那么该节点下只有2个子节点
(4) 查找B树时数据可能在非叶子节点中找到，而对于B+树不管是聚簇索引还是二级索引，数据最终都要查到叶子节点上



若某张表的数据特别大，超出了页大小的容量限制，数据是如何存储的?
若叶子节点页每页只能存储一条记录，那么B+数的叶子节点就退化成了链表，类似的B+树就退化成了跳跃表。
为了避免这种情况发生，需要每个页至少保存两条记录。这样就要求每条记录的大小不超过 8K .
那么当记录大小超过8K的话，数据该如何存储呢？
InnoDB 数据页中数据行的存储具有不同的行格式
(1) 如果是compact 的行格式 就将该记录的前768个字节保存在叶子节点中，然后将剩下的部分保存在另一个新开的页中，
通过定义额外的指针指向该新开的指针来访问完整的数据。
(2) 如果是dynamic 的行格式，实际的行数据全部保存在新开的几个页中,数据页只会保存指向保存数据新开页的指针。

MySQL 5.7 及8.0 开始，InnoDB 默认的行格式该成了 Dynamic, 因此当数据页中行溢出时，数据的存储是以以上(2)的方式进行的
若表定义中不可避免存在大字段,那么可以考虑使用 MyISAM存储引擎,因为MyISAM记录数据与索引数据在存储是上分离的，因此不会出现行溢出
此外还可以增大page_size 的大小(修改源代码的方式)为32K或者64K


索引的类型可以按照不同维度来分类
(1)逻辑上来看
索引可以分为: 普通索引,唯一索引,主键索引等
(2)按照作用字段数量来看
可以分为: 单列索引 和 联合索引
(3)按照物理存储方式上来看
可以分为: 聚簇索引和二级索引


索引的应用(SQL调优):
(1) 索引的设计原则
频繁用作where查询条件的字段
经常被order by 或者 group by 的字段
distinct 的字段创建索引
varchar 类型的字段创建索引指定长度(使用字符串前缀来创建) order by 可能不准
创建联合索引,使用频率更高的字段放在最左边
优先使用区分度高的字段创建索引(使用频率差不多的情况下)
多个字段需要创建索引段的情况下,联合索引优于单值索引

经常更新的字段不要创建索引
无序的值不建议创建索引

(2) 索引失效注意事项










2. 说一说MySQL的事务？
什么是事务? 有哪些特性? 特性是怎么实现的？事务如何做到隔离? RR隔离级别是如何实现的？


3. MySQL中有哪些锁?他们有什么用途?


4. MySQL中有哪些日志? 它们分别有什么用途?
mysql 中日志可以分为: 二进制日志, 错误日志, 通用查询日志,慢查询日志,重做日志 和 回滚日志。

二进制日志(binlog): 记录对表记录进行修改操作的日志，一般用于数据的主从同步，数据备份。
    binlog 有三种工作模式: 行模式,statement 模式 和 mixed 模式


错误日志: 记录mysql启动,运行，停止过程中出现的问题，方便我们了解服务器的状态。
通用查询日志: 记录用户所有的操作，包括建立连接，释放连接，执行的SQL指令等。
慢查询日志: 记录查过long_query_time 阈值的查询操作的日志.
重做日志: WAL机制下修改数据前先记录的日志，用于宕机后数据的恢复。
回滚日志: 回滚段中保存的日志，用于事务的回滚和MVCC机制的实现。



5. 比较一下存储引擎 InnoDB 和 MyISAM？
(1) InnoDB 支持外键，MyISAM 不支持
(2) InnoDB 支持事务，MyISAM 不支持事务
(3) 如果存在大量更新和删除时，InnoDB 效率更高
    如果存在大量的插入和查询, 那么MyISAM 效率更高
    (为什么?)
(4) InnoDB支持行锁, MyISAM仅支持表锁
(5) 由于不支持事务,崩溃后无法安全恢复
(6) MyISAM 节省资源,消耗少,业务简单；InnoDB 并发写，支持事务，资源消耗大



6. InnoDB底层存储结构?与B+树的关系？
InnoDB文件存储按照从记录到 .ibd 文件的顺序来看，具有如下关系:

记录行 ==> 数据页 ==> 区 ==> 段 ==> 表空间文件

-> 其中记录行就是包含用户表记录的数据,除了用户数据外还有 next record 指针, record type 等记录头信息
-> 数据页默认大小为 16K, 页作为数据与磁盘交互的基本单位，一个页会包含多条记录，页之间通过首尾指针连接，此外还维护者一些记录数量,页目录等信息
-> 为了让B+树种叶子几点逻辑上前后相邻的页在物理上也具有相邻的特性，以此来提高批量数据查询效率，
   InnoDB在页结构之上使用区来存储多个数据页，每个区中包含64个数据页，这样一次磁盘IO可将多个逻辑相邻的数据页加载内存
-> 段是InnoDB 组织数据的基本单位，例如表有数据段(叶子节点段),索引段(非叶子节点段),回滚段等，InnoDB中同一个表中所有的数据都存储在(8.0以后).ibd文件中
   因此InnoDB 需要通过搜索在.ibd 文件中搜索段才能找到对应的数据或者索引，这样直接定位可以减少在同一个文件中搜索的范围。(不考虑碎片区的情况)
-> 表空间文件也就是 .ibd 文件，是InnoDB 数据存储的文件,数据的落盘处理就是落到该文件

B+树中不论叶子节点还是非叶子节点都是以数据页的形式组织的，当内存中B+树的节点发生修改后需要落盘时，是将通过对应的节点找到它在
.ibd 文件中的段，然后找到它在段中的某个区，在区中定位出对应的数据页，最后将数据写入进去。


############################################# 三 Redis (熟练原理&灵活应用) #########################################
1. Redis 有哪些数据结构? 它们底层是如何实现的？(Hash,Zset)

2. Redis 是单线程的为什么还这么快?

3. Redis 如何保证数据不丢失? 若是集群模式下如何保证?
I、非高可用情况下保证: 数据持久化(牺牲可用性保证可靠性)
Redis数据持久化有哪些方案? 两种持久化方案的工作机制? 数据如何刷盘?

II、高可用情况下保证: 集群节点故障后如何处理保证数据不丢失


4. 介绍一下Redis 集群?
Redis有哪些工作模式? 集群模式与主从模式的关系? 集群槽位划分(节点上下线)? 主从之间数据同步方式?
为什么Redis集群数据同步没有采用Kafka集群的acks=all的方式?




################################################ 四 分布式组件 (事务和锁) ###########################################
1. 分布式锁用redis 或 zookeeper分别怎么实现?


2. 分布式事务两阶段提交？TCC实现分布式事务的原理? Seata分布式事务的原理及注意事项?



################################################ 五 JDK (并发&JVM&集合) ###########################################

1. JVM 如何有如何判断对象是否存活？有哪些垃圾收集算法？对应的又是哪些垃圾收集器?
JVM 判断对象是否存活主要 有引用计数法 和 可达性分析法 两种方法。
由于引用计数法存在循环引用的问题，因此JVM 虚拟机hotspot 采用的是可达性分析法。
可达性分析法，简单而言就是 通过设定一些GC Root, 从这些Root 出发遍历所有的树形引用
若对象没有出现在引用树上，就认为是可回收对象。常见的GC Root 有
a) 方法栈中的引用型变量
b）类静态属性及常量
c) 本地方法栈中的应用型变量
d) 虚拟机内部Class对象
e) 被同步锁持有的对象

JVM对垃圾收集采用分代收集的方式，用到的垃圾收集算法有
(1) 标记-清除法: 标记清除法采用先标记垃圾，然后将垃圾清除掉的方式回收
    它的问题在于标记阶段可能需要标记大量的垃圾，这样标记过程可能会存在性能问题，从而导致标记时性能不稳定
    另外再清除阶段，将垃圾清除后造成了堆区空间的不连续
(2) 标记-复制法:将内存划分区域,一部分使用，另一部分空闲，每次在使用的区域内将存活对象标记下来，然后将它们复制到空闲区域
    标记复制法在当存在大量朝生夕灭的对象时，可以只复制一小部分，并且由于使用复制的方式，回收垃圾的同时
    还保证了回收后区域的连续性。
    这种回收算法的问题在于，如果对象大多数都是存活的，需要复制的对象就会特别多，会存在严重的性能问题。
(3) 标记-整理法: 标记整理法也是先标记，然后将对象这里到内存区域的连续区域，整理完之后可回收对象被清理同时也没有内存区域的间断。
    标记整理法同样也存在性能问题,如需要回收区域的对象大多数都是存活的，在整理时也需要移动大量的存活对象，相较于标记复制的好处是
    不需要预留一部分空闲的内存空间。

常用的垃圾收集器，及搭配使用组合
标记-复制:
    标记复制算法主要用于新生代的垃圾回收,包括 Serial, ParNew,Parallel Scavenge 收集器都是使用的复制算法
    其中 Serial 是单线程进行回收, ParNew 是使用多线程进行回收 而 Parallel Scavenge 则是一款专注于吞吐量的垃圾收集器，
    譬如对于计算密集型的应用，更多的是希望譬如100s 内更多的时间花在计算上。前面的 Serial,ParNew 都是专注于停顿时间，则是IO密集型需要的
    同时 Parallel Scavenge区别于其它新生代垃圾收集器的一个重要特征是 它提供了自适应的细节参数，这就省去了研发人员的参数配置过程

标记-清除:
    CMS垃圾收集器是 Concurrent Mark Sweep 并发标记清除的首字母简称，也是经典垃圾收集器中唯一一个使用标记清除算法的收集器。
    它用于老年代的垃圾收集。CMS也是一款跨时代的垃圾收集器，区别之处在于它不需要stop the world 而是可以和用户线程一起运行并发的
    执行垃圾收集(并发标记&并发清除)。
    CMS垃圾收集器存在以下两个主要问题
    (a) 会存在浮动垃圾: 垃圾标记和清除过程都是并发完成的，在清除过程中是会出现新的垃圾，这就要求触发垃圾清除的老年代使用率不能
    是100% 而要比这个小, 譬如70%, 剩下的30% 用于GC时存放新产生的老年代对象。
    (b) 会存在碎片问题: CMS 使用的是标记清除算法,标记清除算法由于清除后造成了堆区内存的不连续,因此多次GC之后会看到
    老年代明明还有空间，但是就是不能被使用，就是因为大对象需要的连续空间不够。CMS提供了 CMSFullGCsBeforeCompaction参数来进行
    空间的整理，利用该参数可以设置每隔多少次Full GC 执行一次内存空间的压缩整理。

标记-整理:
    标记整理算法一般用在老年代的垃圾收集上，使用该算的垃圾收集器有 Serial Old 和 Parallel Old.
    Serial Old 是 Serial 的老年代版本。而 Parallel Old 则是 Parallel Scavenge 的老年代版本。



2. 线上出现OOM问题，该如何进行问题定位?
OOM内存溢出按照不同维度划分可能有不同的情况 按照OOM报错内存分类可能有 栈区内存不够,堆区内存溢出,元空间内存溢出
按照业务的角度可能有: 代码中对大块数据进行处理(如查询不分页),连接服务端不释放连接导致连接占用大量内存等

下面主要从内存分类的角度来分析内存溢出的可能情况并给出一般化的定位方式
(1)栈区内存不够:
报错-> java.lang.OutOfMemoryError: java.lang.StackOverflowError
栈区内存溢出，跟栈空间总大小及每个线程栈最的空间大小有关；栈的总空间大小跟系统有关，不可设置。但是每个线程栈帧的大小
可以通过参数 -Xss 设置，-Xss设置的越大可以启动线程数就约多。
此外 如果某个线程内使用递归调用，递归嵌套数量太大也会导致 StackOverflowError。
因此 总结来看可以通过 -Xss参数设置 和 递归代码改造来解决栈区内存不够的问题。

定位方式:
总线程数太多导致栈空间不够分配给线程:
线程栈总可用内存 = JVM进程占用内存 -（-Xmx的值）- （-XX:MaxPermSize的值）- 程序计数器占用的内存
通过 jinfo 指令可以查看到 VM的参数配置，利用 top pid 可以查看到当前有多少个线程，然后通过上述公式
可以计算出总栈空间大小SS, SS - 线程数 * Xss 配置的栈大小 得到的结果是否特别小或者接近0, 如果是这样说明栈的总空间偏小
或者需要起更多节点来应对并发。

方法递归调用嵌套太多导致线程栈溢出:
异常栈信息中存在大量同名嵌套，这种情况就属于当个线程栈的栈空间溢出。

(2)堆区内存溢出:
报错-> java.lang.OutOfMemoryError:Java heap space
堆内存溢出可能的情况有:内存分配空间太小,内存泄露等
> 对于内存分配空间大小问题,刻意通过jinfo查看, 修改配置后可以解决

> 而对于内存泄露可以通过jmap -histo:live pid | more 指令查看按各类对象大小倒序排序的
  可以看到哪些对象占用的对空间明显较多，若对象是自定义的类对象可以再代码中review 找出问题代码。
  若非自定义代码可以


(3)元空间内存溢出:
报错-> java.lang.OutOfMemoryError: PermGen space
元空间一般不参与垃圾回收, 这部分内存溢出需要考虑是否是代码中使用了大量的反射等处理


3. 类加载过程?什么是双亲委派制?为什么使用双亲委派?





################################################ 六 系统设计(项目&临时设计) #########################################
1. 并发系统设计? 发红包/活动秒杀 等。
   活动商品秒杀:
   (1) 使用Redis 存储商品信息,redis先扣减，扣减成功后使用MQ异步保存用户-订单-商品信息
   (2) 使用 watch 乐观锁机制配合管道+事务完成批量指令的发送和执行
   (3) 当watch 的k-v 发生变更, 管道指令在执行时会返回NULL,若执行失败,返回的结果列表为空
       通过对 pipeline.execute() 的放回结果进行判断，可知当前执行执行有没有获取到锁，是否执行成功
   (4) MQ消费端消费生成 用户-订单-商品 的抢购记录(如何确保消息不丢失?)
   (5) 用户抢购之后抢断保存状态,首次查询未获取到数据提示重试,首次查询到之后缓存订单数据,之后每次查看不再走后端请求


   分抢十亿红包(金额随机,不能重复领取):


2. 功能系统设计? 如网站上看到的评论,弹幕,访问记录,分类排序等。


############################################## 七 其它 (网络,系统,Maven,Git) ######################################
1. 系统进程间通信有哪些方式?

2. Nginx 实现网关功能参数?

############################################## 八 Spring Cloud 组件 ############################################
1. sentinel 有哪些功能? 它的工作原理是怎么样的?
sentinel 可以提供限流,降级 和 熔断等功能。
sentinel 限流使用的是一种近似的 滑动时间窗算法，具体来讲  它在时间窗内划分多个样本窗，然后以样本窗为统计请求次数的最小时间粒度，否则
滑动时间窗将面临大量的重复统计。 假设一个时间窗被分隔成为 N 个样本窗, 那么当某次请求进来时,会将该请求进来时间落在样本窗统计值+1，然后判断
当前样本窗和之前统计的N-1 个样本窗 所有统计值加起来是否超过了阈值，若超过则阻塞请求。



2. nacos 注册中心工作原理? 它和eureka, zookeeper 的区别?



3. 比较一下 paxos, zab 和 raft协议之间的区别?







############################################## 九 算法题  ######################################################

按照标签刷中等难度题:
数   组:[581,260]
链   表:[]
排   序:[]
动态规划:[]
哈 希 表:[]
   栈  :[]
队    列:[]
双 指 针:[]
滑动窗口:[]




